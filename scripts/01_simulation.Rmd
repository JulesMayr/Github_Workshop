---
title: "Simulation procedure"
author: "Julia Mayr"
date: "17/05/2024"
output: html_document
---

This document represents the landscape simulations discussed in the **METHODS** section of the manuscript.

While this can be seen as one big simulation, to make it easier to think through and understand, it is split up into several different parts:
* Part1: Calculating stability metrics at the sub-plot level
  ** this essentially represents stability at the smallest scale (Area = 1)
* Part 2: Aggregate plots so that beta diversity is maintained at 1 and scale is increased 
  ** this means we manipulate scale without manipulating species compositions
  ** the species compositions will be used and aggregated step-wise from 2-8 communities according to the original design

*Other Parts of the simulation are not included for the purpose of this course!*

```{r Setup, results = FALSE} 

knitr::opts_chunk$set(echo = TRUE)
# Sets the R markdown options so that the code is displayed in the final html file. If it is set to FALSE then the code isn't displayed only the result is

rm(list = ls()) # clears my global environment

# Load libraries needed
library(vegan) # calculate diversity metrics - without this package the Wang et al. Function does not work
library(dplyr) # data manipulation
library(tidyr) # data manipulation
library(knitr) # data manipulation

# load data
load("../data/raw/fake_data_11sp.RData")


# load VariancePartitioning Function for the calculation of stability metrics
source("../scripts/Wang_et_al_2019_VariancePartitioning.r")

options(stringsAsFactors = F)

```

# Part 1: Retrieve Stability metrics at the sub-plot level
  
  *NOTE*: Here it is less of a simulation, but rather an calculation of stability metrics across all the years sampled (i.e. 4) for every subplot.
```{r beta_div1 & Area1, results = FALSE}

# create new dataframe to store stability metrics per scale
variability_data_scale1 <- data.frame(sampleID = character(), CompID = character(), div = numeric(), Species_var = numeric(), Alpha_var = numeric(), Metapopulation_var = numeric(), Gamma_var = numeric(), Pop_synch = numeric(), Spatial_synch = numeric(), Species_synch = numeric(), Metapopulation_synch = numeric(), avg_richness = numeric(), Beta_div = numeric(), temp_mean = numeric(), temp_sd = numeric())
## species_var == species variability or population variability
## these are all variability metrics --> stability is the inverse of variability (we are interested in stability, but they will be converted later)

subplot_IDs <- unique(fake_data_11sp$unique_ID) #so that we can call every subplot on its own

# for every subplot_ID:
for (i in 1:length(subplot_IDs)) {
  datax <- fake_data_11sp[fake_data_11sp$unique_ID == subplot_IDs[i], ] # selects a subset that contains rows only for sample i

  if (nrow(datax) == 4) { # tests if there is data for all years, because some subplots only have data for one or two years --> 4 because 4 years of data
    # create a temporary dataset to store selected information
    temp <- datax[1, c("unique_ID", "sown_species_comp", "div")]

    TH.year <- 4 ### the number of years to be used
    TH.plot <- 1 ### the number of communities

    arrayx <- array(NA, dim = c(ncol(datax) - 5, TH.year, TH.plot)) # -5 to take only the abundance per species data
    # datax has 16 columns in total --> 16 - 5 = 11 --> 11 species in BioCliVE (because ca and ra are taken out)
    # arrayx is a multi-dimensional array of NA's
    ## the number of communities (TH.plot) gives the number of dimensions - when TH.plot = 2 (at scale 2 the number of communities is 2), then there will be 2 matrices
    ### for each community a matrix is created with 11 rows (1 for each species) and 4 columns (1 for each year)

    # fill in this array based on datax, by community and by year
    plotindex <- sort(unique(datax$unique_ID))
    yearindex <- sort(unique(datax$year))

    for (i in 1:TH.plot) { # to loop across the matrices (#TH.plot)
      for (j in 1:TH.year) { # to loop through the years
        tmpdata <- datax[datax$unique_ID == plotindex[i] & datax$year == yearindex[j], -c(1:5)]
        # -c(1:5) makes sure that those columns are disregarded as they do not contain biomass data across years for the individual species
        arrayx[, j, i] <- unlist(tmpdata)
      }
    }

    # Now the variance partitioning function can be applied to this array to obtain the desired variability metrics
    var_part_result <- var.partition(arrayx) # var.partition after Wang et al. 2019

    # extract metrics of interest
    my_metrics <- var_part_result[c(1:9, 14, 16, 17)]

    # store these metrics in a temporary dataframe
    variability_temp <- t(as.data.frame(my_metrics))

    # combine the temporary dataframes to resemble the structure of the empty dataframe created above
    temp <- cbind(temp, variability_temp)

    # add new data from this loop to the last data
    variability_data_scale1 <- rbind(variability_data_scale1, temp)
  }
}

# add Area and rearrange
variability_data_scale1$Areasize <- as.numeric(rep(1, nrow(variability_data_scale1)))
variability_data_scale1 <- variability_data_scale1[, c(16, 1:15)]

# change column names
colnames(variability_data_scale1) <- c("Area", "sampleID", "CompID", "div", "Species_var", "Alpha_var", "Metapopulation_var", "Gamma_var", "Pop_synch", "Spatial_synch", "Species_synch", "Metapopulation_synch", "avg_richness", "Beta_div", "temp_mean", "temp_sd")

# convert variability to stability
stability_conversion <- apply(variability_data_scale1[, 5:12], c(1, 2), function(x) 1 / x) # stability is the inverse of variability
# change colnames accordingly
colnames(stability_conversion) <- c("Species_stab", "Alpha_stab", "Metapopulation_stab", "Gamma_stab", "Pop_AS", "Spatial_AS", "Species_AS", "Metapopulation_AS")
stability_data_scale1_11sp <- cbind(variability_data_scale1[, 1:4], stability_conversion, variability_data_scale1[, 13:16])

```

# Part 2: Simulate beta diversity = 1 across all scales; i.e. maintain the same species compositions and increase area from 2-8

## Step 1. Separate years and then species compositions so that we can subsample within them. 

```{r divide dataset into a list of 4, results = FALSE}

fake_data_11sp$total.biomass <- rowSums(fake_data_11sp[, 6:16])

year.id <- c(1:4) # create a vector containing all the years
comp.id <- factor(unique(fake_data_11sp$sown_species_comp)) # create a vector containing all the species compositions once
data.list.year <- lapply(year.id, function(x) fake_data_11sp[fake_data_11sp$year == x, ])
## lapply(v,function(x) df[df$col==x]) uses a simple function defined in the call --> the function subsets fake_data_11sp by years and stores that data as lists in year.id with one list for each year --> data.list.year is a list of 4

data.list.comp <- vector(mode = "list") # creates an empty list to store data in for each species composition
for (i in year.id) { # for every year
  data.list.comp[[i]] <- vector(mode = "list", length = length(comp.id)) # create a list for all species compositions
  data.list.comp[[i]] <- lapply(comp.id, function(x) data.list.year[[i]][data.list.year[[i]]$sown_species_comp == x, ]) # subset data by year and species composition
  # data.list.comp is a list of 4 (one list for each year), each containing a list of 43 (one list for each species composition)
}
```

## Step 2. Retrieve Stability Metrics for all other areas (2-8) 

Sample without replacement - this allows to use all unique combinations of subplots for each species composition and area

```{r beta_div1 & Area2-8, results = FALSE}

# create a list of 8 to store data for each area
Areas_unique_11sp <- list(1:8)

############################################################## Step 1: sub-sample Area using data.list.comp  ####################################################

for (A in 2:8) { # loop through areas 2-8 --> we don't want to loop through Area=1 as that is at the community scale

  # make empty dataframe so we can store the data that we need
  plotIDs.scale_area <- vector(mode = "list", length = length(comp.id))
  scale_area <- data.frame(
    year = numeric(), div = numeric(), unique_ID = character(), compID = character(), sampleID = numeric(), an = numeric(), ar = numeric(),
    lu = numeric(), or = numeric(), po = numeric(), tr = numeric(), ve = numeric(), fe = numeric(), ru = numeric(), ho = numeric(), kn = numeric(),
    total.biomass = numeric()
  )

  # calculate number of unique combinations possible for a given landscape size:
  # P(n,r) = n!/r!(n-r)!, where n = 8 as we have a total of 8 communities to choose from and n = A as we select A subplots to create a landscape of area A
  resamplings <- factorial(8) / (factorial(A) * factorial(8 - A))

  # create a dataset containing all data of interest for all unique combinations of A plots for a given species composition
  for (j in 1:43) { # loop through each species composition for the first year
    plotIDs.scale_area[[j]] <- matrix(nrow = resamplings, ncol = A + 1) # for each species composition, create an empty matrix to store unique combinations

    # fill that matrix
    if (length(data.list.comp[[1]][[j]]$unique_ID) == 8) { # tests if each species compositions has 8 unique plots --> this is needed because plot 54c is missing
      recombinations <- combn(data.list.comp[[1]][[j]]$unique_ID, A, FUN = NULL, simplify = TRUE) # create all possible unique combinations and store in a matrix/array
      recombinations <- t(recombinations) # transpose the matrix so that it is in a long format
      counter <- ((j - 1) * resamplings) + 1:resamplings # makes sure that each combination of each species composition has a unique count
      recombinations <- cbind(recombinations, counter) # combine
      plotIDs.scale_area[[j]] <- recombinations # assigns such a matrix to each species composition


      # loop through each unique combination
      for (i in 1:resamplings) {
        # create a sample containing only the combination of row i from the matrix of all possible combinations
        year1scale_area <- plotIDs.scale_area[[j]][i, 1:A]
        

        if (A == 2) { 
          # create a temporary data set that has only the subplots we sampled
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2], ]

          # aggregate the data so that we have the summed biomass across our subplots
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)

          # give each sample a unique sample id
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
         
        #repeat same procedure for all other areas
        } else if (A == 3) { 
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[3], ]
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
        } else if (A == 4) {
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[3] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[4], ]
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
        } else if (A == 5) { 
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[3] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[4] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[5], ]
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
        } else if (A == 6) { 
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[3] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[4] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[5] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[6], ]
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
        } else if (A == 7) { 
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[3] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[4] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[5] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[6] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[7], ]
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
        } else if (A == 8) { 
          temp <- data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID == year1scale_area[1] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[2] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[3] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[4] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[5] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[6] |
            data.list.comp[[1]][[j]]$unique_ID == year1scale_area[7] | data.list.comp[[1]][[j]]$unique_ID == year1scale_area[8], ]
          scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
          scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1])
        }

        # add our new data from this run of the loop to the last data
        scale_area <- rbind(scale_area, scale_area.temp)
      }
    }
  }

  ############################################################# Step 2: Take the same plots for all other years ###################################################

  for (k in 2:4) { # loops across the two years
    for (j in 1:43) { # loops across our species compositions
      for (i in 1:resamplings) { # loops across our resamplings
        if (!is.na(plotIDs.scale_area[[j]][i])) { # tests that there is not a NA for the subplot combination --> if there were not 8 subplots, NAs were inserted at
          # plotIDs.scale_area[[j]], which means that this combination cannot be used --> therefore, if there are no NAs, execute the following code

          if (A == 2) { # if Area is 2, i.e. composed of 2 subplots, execute the following, etc.:
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2], ]
            # need to add comment to what exactly I am doing here
            # basically looks for the same unique IDs(in the form a&b or b&a) in all other years and adds them to temp
          } else if (A == 3) { 
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 3], ]
          } else if (A == 4) { 
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 3] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 4], ]
          } else if (A == 5) { 
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 3] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 4] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 5], ]
          } else if (A == 6) { 
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 3] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 4] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 5] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 6], ]
          } else if (A == 7) { 
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 3] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 4] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 5] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 6] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 7], ]
          } else if (A == 8) { 
            temp <- data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 1] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 2] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 3] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 4] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 5] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 6] |
              data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 7] | data.list.comp[[k]][[j]]$unique_ID == plotIDs.scale_area[[j]][i, 8], ]
          }


          if (length(temp$total.biomass) > 0) { # tests if data is present since some species combinations are gone in years 2,3 and/or 4; executes the following code only if data is present for all years
            scale_area.temp <- aggregate(total.biomass ~ year + div + unique_ID + sown_species_comp + an + ar + lu + or + po + tr + ve + fe + ru + ho + kn, data = temp, FUN = sum)
            scale_area.temp$sampleID <- as.numeric(plotIDs.scale_area[[j]][i, A + 1]) # adds in our same sample ids so we can pretend the combinations are basically plots themselves
            # adds our new data from this run of the loop to the last data
            scale_area <- rbind(scale_area, scale_area.temp) # adds the new data to the old data
          }
        }
      }
    }
  }

  ################################################################ Step 3: calculate Variability metrics ##########################################################

  # create new dataframe to store stability metrics per scale
  variability_data_scale_area <- data.frame(sampleID = numeric(), CompID = character(), div = numeric(), Species_var = numeric(), Alpha_var = numeric(), Metapopulation_var = numeric(), Gamma_var = numeric(), Pop_synch = numeric(), Spatial_synch = numeric(), Species_synch = numeric(), Metapopulation_synch = numeric(), avg_richness = numeric(), Beta_div = numeric(), temp_mean = numeric(), temp_sd = numeric())

  # for every landscape (=unique sample id):
  for (i in 1:length(unique(scale_area$sampleID))) {
    datax <- scale_area[scale_area$sampleID == i, ] # selects a subset from scale_area data --> this subset contains rows only for sample i

    if (nrow(datax) == (A * 4)) { 
  
      temp <- datax[1, c("sampleID", "sown_species_comp", "div")]

      TH.year <- 4 ### the number of years to be used
      TH.plot <- A ### for the number of communities --> = area size

      arrayx <- array(NA, dim = c(ncol(datax) - 6, TH.year, TH.plot)) # -7 to take only the abundance per species data

      # fill in this array based on datax, by community and by year
      plotindex <- sort(unique(datax$unique_ID))
      yearindex <- sort(unique(datax$year))

      for (i in 1:TH.plot) { # to loop across the matrices (#TH.plot)
        for (j in 1:TH.year) { # to loop through the years (#TH.year)
          tmpdata <- datax[datax$unique_ID == plotindex[i] & datax$year == yearindex[j], -c(1:4, 16:17)]
          # -c(1:4,16:17) makes sure that those columns are disregarded as they do not contain biomass data across years for the individual species
          arrayx[, j, i] <- unlist(tmpdata)
        }
      }

      # Now the variance partitioning function can be applied to this array to obtain the desired variability metrics
      var_part_result <- var.partition(arrayx) # var.partition after Wang et al. 2019

      # extract metrics of interest
      my_metrics <- var_part_result[c(1:9, 14, 16, 17)]

      # store these metrics in a temporary dataframe
      variability_temp <- t(as.data.frame(my_metrics))

      # combine the temporary dataframes to resemble the structure of the empty dataframe created above
      temp <- cbind(temp, variability_temp)

      # add new data from this loop to the last data
      variability_data_scale_area <- rbind(variability_data_scale_area, temp)
    }
  }

  # add Area and rearrange
  variability_data_scale_area$Areasize <- as.numeric(rep(A, nrow(variability_data_scale_area)))
  variability_data_scale_area <- variability_data_scale_area[, c(16, 1:15)]

  # change column names
  colnames(variability_data_scale_area) <- c("Area", "sampleID", "CompID", "div", "Species_var", "Alpha_var", "Metapopulation_var", "Gamma_var", "Pop_synch", "Spatial_synch", "Species_synch", "Metapopulation_synch", "avg_richness", "Beta_div", "temp_mean", "temp_sd")

  # convert variability to stability
  stability_conversion <- apply(variability_data_scale_area[, 5:12], c(1, 2), function(x) 1 / x) # stability is the inverse of variability
  colnames(stability_conversion) <- c("Species_stab", "Alpha_stab", "Metapopulation_stab", "Gamma_stab", "Pop_AS", "Spatial_AS", "Species_AS", "Metapopulation_AS")
  stability_data_Area_A <- cbind(variability_data_scale_area[, 1:4], stability_conversion, variability_data_scale_area[, 13:16])

  ###########################################################  store data for Area of size A in Areas[[A]]  ##########################################################

  Areas_unique_11sp[[A]] <- stability_data_Area_A
}
```

# Merge and save

```{r merge and save, results = FALSE}

# collapse list into 1 dataset
Beta1_all_scales <- do.call("rbind", Areas_unique_11sp)

# add a column indicating the intended Beta diversity level for my own reference
Beta1_all_scales$Intended_BetaDiv <- as.numeric(rep(1, nrow(Beta1_all_scales)))

# save as .RData so that it is easier to re-use
save(Beta1_all_scales, file = "../data/temp/Beta1_all_scales.RData")
```

```{r end}
sessionInfo()
```

